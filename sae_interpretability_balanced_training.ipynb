{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493629d-7ab1-4a99-892b-778f8b4ac5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sae import TopKSAE, SAELoss\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3735a49e-d0fe-437d-bdf7-b21eab62aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(a=\"SAE Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1485ec-3219-48f2-8f31-47da2299578a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e3cc2e-6dc7-4cf8-9515-f367e73c4a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(load_dataset(\"jam963/indigeneity_fr\", split=\"train\"))\n",
    "df[\"embedding\"] = df[\"embedding\"].map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "933e6d4d-244a-405d-8011-9a7c03e315d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"periods_1825_1950_10.json\", \"r\") as f:\n",
    "    time_periods = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3cf9e6-bc25-476b-be8c-f40136098bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.stack(df.embedding.tolist())\n",
    "\n",
    "# Standardize embeddings \n",
    "mean = np.mean(embeddings, axis=0)\n",
    "std = np.std(embeddings, axis=0)\n",
    "std = np.where(std == 0, 1e-7, std)\n",
    "df[\"embedding\"] = ((embeddings - mean) / std).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dddddcce-a053-47a7-ba5d-bf298e5fb19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>sentence</th>\n",
       "      <th>term</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>creator</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>language</th>\n",
       "      <th>relation</th>\n",
       "      <th>length</th>\n",
       "      <th>genre</th>\n",
       "      <th>embedding</th>\n",
       "      <th>sen_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004976.json</td>\n",
       "      <td>de La- martine et Victor Hugo se rattachent, a...</td>\n",
       "      <td>indigène</td>\n",
       "      <td>4976</td>\n",
       "      <td>Histoire de la littérature française sous la R...</td>\n",
       "      <td>Nettement, Alfred</td>\n",
       "      <td>J. Lecoffre (Paris)</td>\n",
       "      <td>1853</td>\n",
       "      <td>monograph</td>\n",
       "      <td>fre</td>\n",
       "      <td>ark:/12148/cb37273565t</td>\n",
       "      <td>116867</td>\n",
       "      <td>Littérature française</td>\n",
       "      <td>[-1.9171812741988257, -2.2278929959485767, 0.7...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004976.json</td>\n",
       "      <td>En littérature, il conti- nuait ses doctrines ...</td>\n",
       "      <td>indigène</td>\n",
       "      <td>4976</td>\n",
       "      <td>Histoire de la littérature française sous la R...</td>\n",
       "      <td>Nettement, Alfred</td>\n",
       "      <td>J. Lecoffre (Paris)</td>\n",
       "      <td>1853</td>\n",
       "      <td>monograph</td>\n",
       "      <td>fre</td>\n",
       "      <td>ark:/12148/cb37273565t</td>\n",
       "      <td>116867</td>\n",
       "      <td>Littérature française</td>\n",
       "      <td>[-1.1204840080007559, -0.21415018738329644, -0...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006815.json</td>\n",
       "      <td>J'appelle causes positives, celles qui modifie...</td>\n",
       "      <td>indigènes</td>\n",
       "      <td>6815</td>\n",
       "      <td>Race et milieu social : essais d'anthroposocio...</td>\n",
       "      <td>Vacher de Lapouge, Georges (1854-1936). Auteur...</td>\n",
       "      <td>M. Rivière (Paris)</td>\n",
       "      <td>1909</td>\n",
       "      <td>monograph</td>\n",
       "      <td>fre</td>\n",
       "      <td>ark:/12148/cb31515687b</td>\n",
       "      <td>108554</td>\n",
       "      <td>Sociologie</td>\n",
       "      <td>[0.42317150320799435, -0.510985201874166, 0.61...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006815.json</td>\n",
       "      <td>Elles tendent sans cesse à rendre aux indigène...</td>\n",
       "      <td>indigènes</td>\n",
       "      <td>6815</td>\n",
       "      <td>Race et milieu social : essais d'anthroposocio...</td>\n",
       "      <td>Vacher de Lapouge, Georges (1854-1936). Auteur...</td>\n",
       "      <td>M. Rivière (Paris)</td>\n",
       "      <td>1909</td>\n",
       "      <td>monograph</td>\n",
       "      <td>fre</td>\n",
       "      <td>ark:/12148/cb31515687b</td>\n",
       "      <td>108554</td>\n",
       "      <td>Sociologie</td>\n",
       "      <td>[-1.49437695570914, -0.1559418505879319, 0.931...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0006815.json</td>\n",
       "      <td>Les nègres d'Améri- que sont le seul exemple t...</td>\n",
       "      <td>indigènes</td>\n",
       "      <td>6815</td>\n",
       "      <td>Race et milieu social : essais d'anthroposocio...</td>\n",
       "      <td>Vacher de Lapouge, Georges (1854-1936). Auteur...</td>\n",
       "      <td>M. Rivière (Paris)</td>\n",
       "      <td>1909</td>\n",
       "      <td>monograph</td>\n",
       "      <td>fre</td>\n",
       "      <td>ark:/12148/cb31515687b</td>\n",
       "      <td>108554</td>\n",
       "      <td>Sociologie</td>\n",
       "      <td>[0.3046182655151907, 0.1384508724158276, 0.021...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name                                           sentence       term  \\\n",
       "0  0004976.json  de La- martine et Victor Hugo se rattachent, a...   indigène   \n",
       "1  0004976.json  En littérature, il conti- nuait ses doctrines ...   indigène   \n",
       "3  0006815.json  J'appelle causes positives, celles qui modifie...  indigènes   \n",
       "4  0006815.json  Elles tendent sans cesse à rendre aux indigène...  indigènes   \n",
       "5  0006815.json  Les nègres d'Améri- que sont le seul exemple t...  indigènes   \n",
       "\n",
       "     id                                              title  \\\n",
       "0  4976  Histoire de la littérature française sous la R...   \n",
       "1  4976  Histoire de la littérature française sous la R...   \n",
       "3  6815  Race et milieu social : essais d'anthroposocio...   \n",
       "4  6815  Race et milieu social : essais d'anthroposocio...   \n",
       "5  6815  Race et milieu social : essais d'anthroposocio...   \n",
       "\n",
       "                                             creator            publisher  \\\n",
       "0                                  Nettement, Alfred  J. Lecoffre (Paris)   \n",
       "1                                  Nettement, Alfred  J. Lecoffre (Paris)   \n",
       "3  Vacher de Lapouge, Georges (1854-1936). Auteur...   M. Rivière (Paris)   \n",
       "4  Vacher de Lapouge, Georges (1854-1936). Auteur...   M. Rivière (Paris)   \n",
       "5  Vacher de Lapouge, Georges (1854-1936). Auteur...   M. Rivière (Paris)   \n",
       "\n",
       "   date       type language                relation  length  \\\n",
       "0  1853  monograph      fre  ark:/12148/cb37273565t  116867   \n",
       "1  1853  monograph      fre  ark:/12148/cb37273565t  116867   \n",
       "3  1909  monograph      fre  ark:/12148/cb31515687b  108554   \n",
       "4  1909  monograph      fre  ark:/12148/cb31515687b  108554   \n",
       "5  1909  monograph      fre  ark:/12148/cb31515687b  108554   \n",
       "\n",
       "                   genre                                          embedding  \\\n",
       "0  Littérature française  [-1.9171812741988257, -2.2278929959485767, 0.7...   \n",
       "1  Littérature française  [-1.1204840080007559, -0.21415018738329644, -0...   \n",
       "3             Sociologie  [0.42317150320799435, -0.510985201874166, 0.61...   \n",
       "4             Sociologie  [-1.49437695570914, -0.1559418505879319, 0.931...   \n",
       "5             Sociologie  [0.3046182655151907, 0.1384508724158276, 0.021...   \n",
       "\n",
       "   sen_len  \n",
       "0       59  \n",
       "1       85  \n",
       "3       52  \n",
       "4       37  \n",
       "5       37  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d353b-2327-4ba1-b4fc-c5943a81279b",
   "metadata": {},
   "source": [
    "## SAE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5e871d7-204a-420b-b95c-9b4bb533ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data_by_time_period(df, time_periods):\n",
    "    data_by_period = defaultdict(list)\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        year = row['date']\n",
    "        for period, (start, end) in time_periods.items():\n",
    "            if start <= year <= end:\n",
    "                data_by_period[period].append((i, df.iloc[i][\"embedding\"]))\n",
    "                break\n",
    "    \n",
    "    empty_periods = [period for period, data in data_by_period.items() if len(data) == 0]\n",
    "    if empty_periods:\n",
    "        print(f\"Warning: The following periods have no data: {', '.join(empty_periods)}\")\n",
    "    \n",
    "    return data_by_period\n",
    "\n",
    "def balanced_sample(data_by_period, sample_size):\n",
    "    sampled_data = []\n",
    "    for period, data in data_by_period.items():\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "        if len(data) < sample_size:\n",
    "            sampled = data\n",
    "            print(f\"Warning: Period {period} has fewer samples ({len(data)}) than the requested sample size ({sample_size})\")\n",
    "        else:\n",
    "            sampled = random.sample(data, sample_size)\n",
    "        sampled_data.extend(sampled)\n",
    "    random.shuffle(sampled_data)\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb2beb8-8c8c-4c83-869b-4698b9c12271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_balanced_topk_sae(model, df, time_periods, total_steps, learning_rate, batch_size, device, \n",
    "                            dead_latent_update_pct=1.0,\n",
    "                            sample_size_pct=1.0,\n",
    "                            n_latents=768*2,\n",
    "                            k_active=16):\n",
    "\n",
    "    \n",
    "    data_by_period = group_data_by_time_period(df, time_periods)\n",
    "    non_empty_periods = [period for period, data in data_by_period.items() if len(data) > 0]\n",
    "    if not non_empty_periods:\n",
    "        raise ValueError(\"No data available for any time period\")\n",
    "    \n",
    "    min_period_size = min(len(data) for period, data in data_by_period.items() if len(data) > 0)\n",
    "    sample_size = int(sample_size_pct * min_period_size)\n",
    "    \n",
    "    print(f\"Sample size per period: {sample_size}\")\n",
    "    for period, data in data_by_period.items():\n",
    "        print(f\"Period {period}: {len(data)} samples\")\n",
    "        \n",
    "    samples_for_dead_latent_update = round(len(df)*dead_latent_update_pct)\n",
    "    \n",
    "    criterion = SAELoss(n_latents, k_active, samples_per_epoch=samples_for_dead_latent_update).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    writer = SummaryWriter()\n",
    "    global_step = 0\n",
    "\n",
    "    training_total_loss, training_aux_loss, training_dead_latents = [], [], []\n",
    "    \n",
    "    while global_step < total_steps:\n",
    "        sampled_data = balanced_sample(data_by_period, sample_size)\n",
    "        if not sampled_data:\n",
    "            raise ValueError(\"No data sampled for training\")\n",
    "        \n",
    "        for i in range(0, len(sampled_data), batch_size):\n",
    "            batch_indices, batch_embeddings = zip(*sampled_data[i:i+batch_size])\n",
    "            batch = torch.tensor(batch_embeddings, dtype=torch.float32).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            x_recon, h_sparse, h = model(batch)\n",
    "            \n",
    "            loss, mse_loss, aux_loss = criterion(batch, x_recon, h_sparse, model.encoder, model.decoder)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_total_loss.append(loss.item())\n",
    "            training_aux_loss.append(aux_loss.item())\n",
    "            if hasattr(criterion, \"dead_latents\"): \n",
    "                training_dead_latents.append(criterion.dead_latents.sum().item())\n",
    "            else: \n",
    "                training_dead_latents.append(0)\n",
    "            \n",
    "            if global_step % 100 == 0:\n",
    "                writer.add_scalar('Loss/total', loss.item(), global_step)\n",
    "                \n",
    "                # Log grad norms\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        grad_norm = param.grad.norm().item()\n",
    "                        writer.add_scalar(f'grad_norm/{name}', grad_norm, global_step)\n",
    "                \n",
    "                # Log weight norms\n",
    "                for name, param in model.named_parameters():\n",
    "                    weight_norm = param.norm().item()\n",
    "                    writer.add_scalar(f'weight_norm/{name}', weight_norm, global_step)\n",
    "                \n",
    "                # Log sparsity\n",
    "                sparsity = (h == 0).float().mean().item()\n",
    "    \n",
    "                writer.add_scalar('Sparsity/hidden', sparsity, global_step)\n",
    "        \n",
    "                writer.add_scalar('Loss/aux', aux_loss, global_step)\n",
    "            \n",
    "            global_step += 1\n",
    "    \n",
    "    writer.close()\n",
    "    return model, sample_size, {\"total_loss\": training_total_loss, \"aux_loss\": training_aux_loss, \"dead_latents\": training_dead_latents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c55dceb0-9421-441b-8f54-69522e6a321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014f8716-f387-451e-afe1-f3dc6aeeceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(df.embedding.iloc[0]) \n",
    "d_multiple = 4\n",
    "n_latents = int(input_dim*d_multiple)\n",
    "k_active = 8\n",
    "samples_per_epoch = df.shape[0]\n",
    "batch_size = 1024\n",
    "total_steps = 20000\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc5f5bda-c8ca-4ca4-ada9-9645a5b95b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size per period: 4942\n",
      "Period 1851-1875: 4942 samples\n",
      "Period 1901-1925: 92767 samples\n",
      "Period 1876-1900: 67331 samples\n",
      "Period 1926-1950: 39823 samples\n",
      "Period 1825-1850: 5442 samples\n"
     ]
    }
   ],
   "source": [
    "model = TopKSAE(input_dim, n_latents, k_active).to(device)\n",
    "\n",
    "trained_model, sample_size, training_stats = train_balanced_topk_sae(model, \n",
    "                                                                    df, \n",
    "                                                                    time_periods, \n",
    "                                                                    total_steps, \n",
    "                                                                    learning_rate, \n",
    "                                                                    batch_size, \n",
    "                                                                    device,\n",
    "                                                                    n_latents=n_latents,\n",
    "                                                                    k_active=k_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af05602a-7ac2-48d1-8431-5b34efed2138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/4096_8_-1/SAE.pth\n",
      "Hyperparameters saved to models/4096_8_-1/hyperparams.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def save_model_and_hyperparams(model, hyperparams, base_dir='models'):\n",
    "    model_dir = f\"{hyperparams[\"n_latents\"]}_{hyperparams[\"k_active\"]}_{hyperparams[\"hidden_state\"]}\"\n",
    "    \n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    os.mkdir(os.path.join(base_dir, model_dir))\n",
    "    \n",
    "    # Save model\n",
    "    model_filename = \"SAE.pth\"\n",
    "    model_path = os.path.join(base_dir, model_dir, model_filename)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    # Save hyperparameters\n",
    "    hyperparams_filename = \"hyperparams.json\"\n",
    "    hyperparams_path = os.path.join(base_dir, model_dir, hyperparams_filename)\n",
    "    with open(hyperparams_path, 'w') as f:\n",
    "        json.dump(hyperparams, f, indent=4)\n",
    "    print(f\"Hyperparameters saved to {hyperparams_path}\")\n",
    "    return model_dir\n",
    "\n",
    "\n",
    "hyperparams = {\n",
    "    \"embed_mean\": mean.tolist(), \n",
    "    \"embed_std\": std.tolist(), \n",
    "    \"n_latents\": n_latents, \n",
    "    \"k_active\": k_active,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"total_steps\": total_steps,\n",
    "    \"time_periods\": time_periods,\n",
    "    \"sample_size\": sample_size,\n",
    "    \"hidden_state\": -1\n",
    "}\n",
    "    \n",
    "model_dir = save_model_and_hyperparams(trained_model, hyperparams)\n",
    "\n",
    "with open(f\"models/{model_dir}/training_stats.json\", \"w\") as f: \n",
    "    json.dump(training_stats, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99c85e66-b008-4748-8598-5a1c2d79f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def generate_sparse_embeddings(model, df, batch_size=1024):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    print(f\"Device: {device}\")\n",
    "    hidden_dim = model.encoder.out_features\n",
    "\n",
    "    all_sparse_embeddings = []\n",
    "    with torch.no_grad(): \n",
    "        for i in tqdm(range(0, len(df), batch_size), desc=\"Processing batches...\"):\n",
    "            batch = torch.tensor(df.embedding.iloc[i:i+batch_size].tolist(), dtype=torch.float32).to(device)\n",
    "            _, h_sparse, _ = model(batch)\n",
    "            h_sparse = h_sparse.cpu().numpy()\n",
    "            all_sparse_embeddings.append(sparse.csr_array(h_sparse))\n",
    "            \n",
    "    all_sparse_embeddings = sparse.vstack(all_sparse_embeddings)\n",
    "    assert len(df) == all_sparse_embeddings.shape[0]\n",
    "    \n",
    "    return all_sparse_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac708dca-5937-4b8d-8ef4-c4113593938d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 206/206 [00:11<00:00, 18.02it/s]\n"
     ]
    }
   ],
   "source": [
    "all_sparse_embeddings = generate_sparse_embeddings(trained_model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "802bc591-150d-4e33-b015-dfe2f418f384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4096_8_-1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "457bb1fa-14ba-496f-acad-1097fa2bac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse.save_npz(f\"models/{model_dir}/sparse_embeddings.npz\", all_sparse_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
